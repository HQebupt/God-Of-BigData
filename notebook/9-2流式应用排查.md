#### 6. 流式计算任务应用排查

PU没有数据，某个Spout的缓存队列满了。

##### 1.原因1：Spout底层传输服务未启动

`jstack`查看Spout进程的所有线程，发现没有负责底层传输的线程：Out、Netty（New I/O）线程。 查看该进程的启动日志，无这些线程的启动日志，也没有相关的错误。 // 待查，未启动的原因

##### 2.原因2：用户的APU代码里面，出现了死循环

`jstack`多次打出堆栈，发现信息没有改变多少。APU、Out线程都存在，都是Runnable的。 `top`看该进程，CPU利用率>100%,怀疑Apu代码里面有死循环，找到线程占用率为99%的线程id:125274, 转换为16进制，查看是Apu线程，而Apu线程一直处于执行`com.sina.suda.miaokai.DealAttribute.getDifference`该方法，查看该方法，有可能会出现死循环。定位到该问题代码，修改。

#### 5.使用OLS jar包与应用的jar包冲突解决办法

1. 把OLS包中依赖的kafka_2.8.0 exclusion掉（此版本依赖的Scala和Tranquility中的冲突）；
2. 把OLS包中依赖的各netty也exclusion掉。

```xml
 <dependency>
   <groupId>com.sina.mis</groupId>
   <artifactId>OLS_Yarn</artifactId>
   <version>0.2.2.1</version>
   <exclusions>
      <exclusion>
         <groupId>com.sina.mis</groupId>
         <artifactId>appMonitorCommon</artifactId>
      </exclusion>
      <exclusion>
         <groupId>org.apache.kafka</groupId>
         <artifactId>kafka_2.8.0</artifactId>
      </exclusion>
      <exclusion>
         <groupId>io.netty</groupId>
         <artifactId>netty</artifactId>
      </exclusion>
      <exclusion>
         <artifactId>netty</artifactId>
         <groupId>org.jboss.netty</groupId>
      </exclusion>
   </exclusions>
</dependency>
```

#### 4.diagnostics: root.dw.dw is not a leaf queue

```
17/01/13 10:17:28 INFO Client:
	 client token: N/A
	 diagnostics: root.dw.dw is not a leaf queue
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1484273853907
	 final status: FAILED
	 tracking URL: N/A
	 user: dw
```

dw下面没有dw的子队列，要有一个子队列。在RM的配置文件`fairScheduler.xml`添加。(不需要重启)

- ResourceManager: `/usr/local/hadoop-2.4.0-ols/etc/hadoop/fairScheduler.xml`

#### 3.workflow.xml配置的内存，没有增大1.25倍的原因

```
<?xml version="1.0" encoding="UTF-8"?>
<workflow>
    <Spouts>
        <Spout>
            <Name>statusfirehose2kafka</Name>
            <Class>firehose_status.FireHoseStatusSpout</Class>
            <CfgString>
                ols.kafka.out.topic=ls_userlevel_login_temp_6;
                ols.kafka.out.brokers=kafka1.hadoop.data.sina.com.cn:19092;
                ols.kafka.out.send.batch=1000;
                ols.kafka.property.rebalance.backoff.ms=5000;
                ols.kafka.property.rebalance.max.retries=10;
            </CfgString>
            <Parallelism>2</Parallelism>
            <OutModel>ROUND</OutModel>
            <inClass>firehose_status.FireHoseStatusInWithZKV2</inClass>
            <Memory>3072</Memory>
            <JavaArgv>-Xmx3072m -XX:+UseParallelGC -XX:-UseGCOverheadLimit -XX:ParallelGCThreads=4	</JavaArgv>
        </Spout>
    </Spouts>
</workflow>
```

- 因为配置了`<Memory>3072</Memory>`,就会按照它与`xmx`的最大值来；若没配置`<Memory>3072</Memory>`，就会按照`xmx*100/80`来分配为最终的内存。详细见class:`MemUtils.java`

#### 2. wiki的ols应用问题案例

##### 2013-12-30

http://general.wiki.erp.sina.com.cn/ols_apps/ad_interaction 项目发生报警，报警现象是pu无法再消费数据，原因是写入hbase的线程，正好写入的regionserver资源非常紧张，导致不能正常写入数据导致

##### 2013-12-31

http://general.wiki.erp.sina.com.cn/bid_bp 项目发生报警， 报警现象是mysql写入数据异常，原因mysql的读操作锁住了表，导致写操作无法进行

- 处理方法：解决mysql读写分离

##### 2014-01-26

2014-01-26 晚间 23:30左右，http://general.wiki.erp.sina.com.cn/ols_apps/ad_interaction 项目发生报警，原因是向hbase追加数据的程序被堵住了。

##### 2014-01-27

2014-01-27 凌晨 6:30左右，诸多相关微博的实时系统发生报警。原因firehose出现故障，无法获取微博原创数据和微博评论数据。

- 处理方法：等待自动恢复

#### 1.OLS 应用程序数据堆积-- StringUtils.split

OLS处理能力不足，TPS几百。jstack查看： String.split性能很差的，能不能不用split，或者用StringUtil。

推荐用前两种，这两个可能是一样的实现。jar包的版本不同。

1. org.apache.commons.lang.StringUtils;
2. org.apache.commons.lang3.StringUtils;
3. org.apache.hadoop.util.StringUtils；

- String.split的堆栈

```
"Apu work thread" prio=10 tid=0x00007fd50cbae800 nid=0xfc6f runnable [0x00007fd50238c000]
   java.lang.Thread.State: RUNNABLE
	at java.util.regex.Pattern$Start.match(Pattern.java:3408)
	at java.util.regex.Matcher.search(Matcher.java:1199)
	at java.util.regex.Matcher.find(Matcher.java:592)
	at java.util.regex.Pattern.split(Pattern.java:1200)
	at java.lang.String.split(String.java:2313)
	at com.sina.mis.ols.ActiveSpout.process(ActiveSpout.java:135)
	- locked <0x000000076045fdf8> (a java.util.HashMap)
	at com.sina.ols.apu.process.AbstractProcessUnit$Worker.run(AbstractProcessUnit.java:474)
	at java.lang.Thread.run(Thread.java:745)
```

- StringUtils.split的堆栈

```
"Apu work thread" prio=10 tid=0x00007fd50cbae800 nid=0xfc6f runnable [0x00007fd50238c000]
   java.lang.Thread.State: RUNNABLE
	at org.apache.hadoop.util.StringUtils.split(StringUtils.java:436)
	at com.sina.mis.ols.ActiveSpout.process(ActiveSpout.java:75)
	- locked <0x000000076045fdf8> (a java.util.HashMap)
	at com.sina.ols.apu.process.AbstractProcessUnit$Worker.run(AbstractProcessUnit.java:474)
	at java.lang.Thread.run(Thread.java:745)

   Locked ownable synchronizers:
	- None
```

hadoop的工具类在包org.apache.hadoop.util下面，为我们提供了一个分割字符串的方法,源码分析：

```java
public static String[] split(
      String str, char separator) {
    // String.split returns a single empty result for splitting the empty
    // string.
    if (str.isEmpty()) {
      return new String[]{""};
    }
    ArrayList<String> strList = new ArrayList<String>();
    int startIndex = 0;
    int nextIndex = 0;
    while ((nextIndex = str.indexOf(separator, startIndex)) != -1) {
      strList.add(str.substring(startIndex, nextIndex));
      startIndex = nextIndex + 1;
    }
    strList.add(str.substring(startIndex));
    // remove trailing empty split(s)
    int last = strList.size(); // last split
    while (--last>=0 && "".equals(strList.get(last))) {
      strList.remove(last);
    }
    return strList.toArray(new String[strList.size()]);
  }
```

